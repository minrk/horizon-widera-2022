\TOWRITE{ALL}{Proofread 1.2 up to 1.2.10}

\TOWRITE{ALL}{Write missing sections 1.2.13 to 1.2.16}

\TOWRITE{Min/Hans}{Mention KPIs somewhere?}

\TODO{Provide contents for empty subsections at the end of section 1.}

\subsection{Methodology}\label{sec:concept_methodology}
\eucommentary{5-8 pages}





% \subsubsection{Concept}%\label{sec:concept}
%
% Open Science is the principle that science, in order to be most
% {impactful} and {socially responsible}, should be done
% {publicly}, with as much of the scientific process and products
% accessible, reviewable, reproducible and reusable by as many members of
% the global community as possible.
%
% There are exciting opportunities for Open Science for almost all academic fields
% in the modern age of computational science. As more and more research takes the
% form of code and/or data, the opportunity to share, reproduce, and reuse
% scientific work is greater than ever, even enabling new forms of
% {interdisciplinary collaboration}, and interoperable and re-usable results and
% tools.
%
%  Simultaneously, there are obstacles -- both technical and social -- to
% making open science and reproducible science a practical reality. The challenges
% include: If a researcher has code and/or data to publish, how is that best
% done? How do researchers learn {best practices for reproducible science} in
% their field? How do previously disconnected fields benefit from each other's
% work as the same computational challenges are faced again and again by different
% communities? How can scientists be encouraged to make their work reproducible?
%
% These are the questions that guide the \TheProject{} project.

\subsubsection{Supporting Open, Useful, and Reproducible Computational
  Environments}\label{sec:SOURCE}

Our project is titled ``\emph{Supporting Open, Useful, and Reproducible Computational Environments.}'':
\begin{itemize}
\item The work done is this project will be \emph{Supporting} scientists in their
  endavours to make their work more reproducible and re-usable.
\item We believe in the value of \emph{Open} science and \emph{Open} source. The
  best reproducibility and re-usability of scientific results is given through
  complete transparency of the steps taken in the derivation of a result. For
  the computational aspects this means to make all simulation and/or
  post-processing and analysis steps open source. While this may not always be
  possible, we advocate such openness as the best practice for reproducible science.

  All work done, including software, training and documentation materials, will
  be open source and available through an open access license.

  (We note that the collective development of the grant proposal you are reading
  is also done as open source, and can be inspected at
  \url{http://github.com/minrk/horizon-widera-2022} for those interested.)

\item Measures towards better reproducibility have to be \emph{Useful} and
  practical: if a proposed approach or tool burdens the scientist with
  additional work, or requires significant additional skills, it becomes less
  likely to be widely accepted.

  The philosophy we support here is that the proposed (Binder) tools for
  reproducibility are based on existing standards which are already
  adopted by many and can be considered best practice.

\item Within the wide field of reproducibility in science, we focus in this
  project on the improvement of the automatic generation of \emph{Reproducible
    Computational Environments}.
  % It is an essential step for reproducible
  % science to be able to setup the correct
  % software environment, before any attempt can be undertaken to reproduce (and
  % thus repeat) the calculation of a result obtained before.
\end{itemize}

\subsubsection{Outline of concept and methodology}

In the following we explain our concept and the technology on which this
proposed project builds in more detail.
\begin{itemize}
\item Sections \fullref{sec:reproducibility} and
  \fullref{sec:reproducibility-challenges} contextualise the proposed work
  within the wide field of reproducibility.
\item Section \fullref{sec:reproducibility-concept} summarises our concept and
  approach concisely.
\item We illustrate the reproducibility discussion with
  \fullref{sec:reproducibility-example} and provide details on some of our
  \fullref{sec:science-applications}.
\item To assist the more detailed description of the concept and the content of
  the Work Packages, we provide a \fullref{sec:terminology}
  and additional technical information in \fullref{sec:project-jupyter} and
  \fullref{seq:project-binder} in our technical appendix that forms
  Section~\ref{sec:appendix} (page~\pageref{sec:appendix}) of this document.
\end{itemize}

\noindent The methodology for this project is discussed starting in section
\fullref{sec:methodology}.


%\TODO{Do we need to keep anything from the commented out lines here?}

%
% With so much research being done that wants to be Open and Reproducible,
% how can we make Science
%
% \begin{enumerate}
%     \item as \textbf{easy} as possible to share and reproduce?
%     \item as \textbf{useful} as possible to other researchers and the public?
% \end{enumerate}
%
%
%
%
%
% \noindent Our plan for \textbf{increasing the reproducibility of scientific results} can be summarised as:
%
% \begin{enumerate}
% \item improve and maintain \textbf{common software infrastructure} used for
%   reproducing computational results,
% \item develop the Jupyter ecosystem to improve capabilities to \textbf{better
%   serve Reproducible Open Science},
% \item \textbf{guide, validate, and demonstrate} our developments through
%   collaboration with a wide variety of application domains,
% \item enable students and researchers to perform Reproducible Open Science through
%   \textbf{training and education}, and improving inclusiveness by focusing
%   these on under-served and under-represented communities
% \end{enumerate}

\medskip

\subsubsection{Reproducibility}\label{sec:concept}\label{sec:reproducibility}

Before describing the focus of the work that we propose here, we want to embed
this into the much wider context of reproducibility challenges.

We will exclude the challenges of reproducing \emph{experimental} data. Our
study starts at the point where such experimental data is available in digital
form.

We will focus on the challenge of computational reproducibility: can we carry out
the same data analysis, creation of figures and tables as they are presented in
a paper, at a later stage, and get to the same results?

Such tables and figures in a publication may be computed from the analysis of
some type of raw data which could originate an experiment, another publication,
a data base, post-processing of another data set or from executing computer
simulations.

% Where additional software, such as analysis scripts, input files
% and software for the simulation are needed,

\subsubsection{Challenges of Reproducibility}\label{sec:reproducibility-challenges}

The challenges of such ``computational reproducibility'' include:
\begin{itemize}
\item Do we know the protocol, \emph{i.e.} are the different
  processing steps for that data recorded? This could be the order in which
  analysis scripts need to be executed -- for example to compute intermediate
  results -- which will be turned into a figure in the last step?

We will call this sequence of steps the \emph{workflow}. This workflow could be
archived -- for example -- through a \softwarename{README.txt} file, or scanned
pages of a hand-written laboratory notebook as a pdf file, or as a
machine-executable script (or a Jupyter notebook).

This is particularly challenging where software is used which can only be
controlled via a Graphical User Interface, as it may require manual recording
and description of the different clicks and steps in laboratory logbook.

\item Are all the scripts and configuration files (and more generally all
software) that are needed in this process known and archived?

\item Where software is involved, have we recorded which version of that
software is needed (or was used)? If compilation is required, do we know which
compilers (and which version) and which additional dependencies are required?

\item Are there instructions how to obtain / compile the required dependencies,
and the software itself (in particular where this is about simulation-based
science or more complex analysis and interpretation software tools)?

\item Where raw data is required, is this archived, accessible, and sufficiently
documented that the format is understandable?
\end{itemize}


\subsubsection{Reproducibility concept}\label{sec:reproducibility-concept}

We can classify the reproducibility challenges listed above into different categories:

\begin{description}
\item[1. Workflow]: Are the processing commands (and their order)
correctly recorded? Do we know which part of the data set the analysis is meant
to be applied to? This is to a significant degree a question of the organisation
and documentation of the research process.

\item[2. Software environment]: Can we recreate the software environment that is
required to execute these commands?

\item[3. Importance]: Is the researcher convinced that investing effort into making
their work more reproducible is a worthwhile investment? This is a wide topic,
touching on expectations, existing cultures, lack of metrics that acknowledge
reproducibility efforts, and policies.

\item[4. Other]: There are other related topics, for example the challenge of
archival of (large) research data sets, of making the data FAIR, and the (for
some domains important) bit-wise reproducibility.
\end{description}

In this proposal, we start from practices that researchers increasingly adopt,
and which we argue are \emph{good reproducibility practices}. We propose to carry
out additional work to \emph{improve the toolset enabling this practice}.

To deal with the \emph{Workflow} challenges, we recommend to automate the
workflow steps as much as possible. In particular, the use of Jupyter Notebooks
to orchestrate the execution of commands seems effective~\cite{Beg2021}.
The use of the notebook is
perceived by many as an improvement of their research effectiveness because
it supports ``Thinking with Code and Data''~\cite{Granger2021}. A such, the
practice of using Notebooks (which helps improving research effectiveness) has
the very positive side effect of making the work more reproducible. (However, we
note that an important task of this project is to support reproducible science
that does not make use of Jupyter Notebooks.)

To deal with the \emph{Software environment} challenge, we recommend to follow
standard practices to describe software requirements. The \emph{focus of this
project is to extend the capabilities of the \repotodocker{} tool} to be able to
\emph{automatically create software environments} based on such software
requirement descriptions.

We can only partially address the \emph{Importance} challenge as this needs
concerted efforts from many stakeholders (such as employers of researchers,
research funders, publishers). However, we will offer training that advocates
the value of open science and that teaches existing best practice in
effective computational science. The step from following such best practice to
making the work reproducible is -- given the Binder tools we want to develop
further here -- relatively small, or even possible without additional effort.

The \emph{Other} challenges are mostly outside the focus of this work
(although our proposal will also assist in reproducible and FAIR data
publishing, see for example Task \taskref{applications}{data-publishing}).


% \subsubsection{Terminology and repository example}\label{sec:reproducibility-example}

\subsubsection{Reproducibility Example}
\label{sec:reproducibility-example}

\begin{figure}[htb]\centering
  \includegraphics[width=0.9\textwidth]{use-cases-binder-logbook-solution.png}
  \caption{A typical use case for Binder-based reproducibility using Jupyter notebooks in research.
            Image by Juliette Belin for the OpenDreamKit project, used under
            CC-BY-SA.}\label{fig:use-cases-binder}
\end{figure}

We start with a description of a use-case making use of existing Binder-based
tools for computational reproducibility. Start from this base-line, we can
explain what progress and additional impact we will enable through this project.

Figure~\ref{fig:use-cases-binder} depicts how a scientist can use a Jupyter
notebook and the Binder software to make her research results easily
reproducible and re-usable. In short:
\begin{itemize}
\item Scientist Jane has created a notebook that carries out computations or
  data processing and creates a figure based on those results. For the purpose
  of the introduction of this workflow, we assume that
  Figure~\ref{fig:reproducibility-example-covid} shows this figure.

\item She has made the notebook and raw data available in a public repository
  (for our example at\newline
  \mbox{\url{https://github.com/fangohr/reproducibility-repository-example}}).

\item As she has described what software is needed to execute her notebook (more
  details below), it is possible for all interested scientists (and anybody
  else, including the reviewers of this proposal) to \emph{reproduce} her
  figure:

  To reproduce the figure, one needs to visit the URL\newline
  \mbox{\url{https://mybinder.org/v2/gh/fangohr/reproducibility-repository-example/HEAD?labpath=figure1.ipynb}}
  in a browser, and then wait a minute or so for a dedicated computational
  environment to be created and started. Then select 'Run' -> 'Run all cells'
  from the menu of the interactive Jupyter notebook that will appear in the
  browser.

  At that point, the computational steps that Jane has carried out to create her
  result are repeated, and the results are \emph{reproduced}.

\item Because all the computational steps are captured in the Jupyter notebook,
  they can be inspected and interrogated if desired. In particular, the steps
  can be modified and re-executed: this allows very efficient \emph{re-use} of
  the results by other researchers.
\end{itemize}

We provide a more detailed description of the components and steps in this
process in the following sections \ref{sec:terminology} to \ref{sec:mybinder}.

The reproducibility workflow shown in Figure~\ref{fig:use-cases-binder} is
working today, and we provide estimates on the number of current users in
section \ref{sec:mybinder}. The work proposed for this project will build on
this existing technology and (i)~make it more robust and easier to use
(\WPref{reproducibility}), and (ii)~extend the functionality (\WPref{impact}) so
that the existing tools can be used in many more use cases
(\WPref{applications}).

We note in particular that the Binder-enabled workflow for reproducibility has
originally been developed to reproduce results that are created within Jupyter
Notebook (as shown in Figure~\ref{fig:use-cases-binder}). As part of this
project, we will extend the Binder tool functionality, so that reproducible
computational environments can be created and used in studies that do not make
use of Jupyter notebooks.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{images/figure1.pdf}
  \caption{Figure (\softwarename{figure1.pdf}) which can be reproduced in our explanatory repository example
    \cite{ReproducibilityRepositoryExample2022}. \label{fig:reproducibility-example-covid}}
\end{figure}

\subsubsection{Science Applications}\label{sec:science-applications}
Throughout this project, we will apply the reproducibility tools to ongoing
research projects that need reproducible processes. This is to inform the
project, evaluate the tools, and provide demonstrators. We expect the
demonstrators we develop to be exploited as production services already during
the grant, and subsequently.

Our science applications follow the workflow outlined in
\ref{fig:use-cases-binder}. \TODO{Mention that some of our science applications need
  additional features, and are not yet supported.}
\begin{itemize}
\item \TODO{Add examples from Ifremer}
\item \TODO{Add examples from UiO}
\item Reproducibility of analysis pipelines and their software
  requirements at the example of a
  Biophysics application\footnote{https://gitlab.mpcdf.mpg.de/MPIBP-Hummer/glycoshield-md}:
  While the compute requirements are moderate and mostly satisfied by Binder in the Cloud,
  the underlying software stack is highly complex (--- it requires the Gromacs simulation
  code (\href{https://www.gromacs.org}{https://www.gromacs.org}), among others
  ---) and poses a particular challenge for long-term reproducibility.
\item Reproducibility of results computed with the ab-initio software Octopus
  (\href{https://octopus-code.org}{https://octopus-code.org}) which provides
  virtual experimentation capabilities. A particular challenge is that Octopus
  is a highly parallelised code and needs HPC computing resources for a
  reproduction of simulation results. A (Slurm) job submission may be required
  to start the reproduction.
\end{itemize}


\subsubsection{Methodology}\label{sec:methodology}

Our approach is centered around the following ideas:
\begin{compactenum}
  \item We put the researcher at the center of our work. In the end,
    researchers are responsible for making their work
    reproducible. It is therefore essential to find technical and social solutions
    that are \emph{useful and practical}. This idea is reflected in researchers
    being involved in \WPref{management} through the \emph{Community Engagegment
    Panel}, the requirements gathering and application of the work carried out
  in \WPref{applications} and the interaction with scientists through our
  outreach and engagement activities in \WPref{education}. All of these inputs
  drive the technical software work done in \WPref{reproducibility} and \WPref{impact}.
\item We also need to consider wishes and constraints from other reproducibility
  stakeholders. These include research councils and funders, publishers, research
  infrastructure providers, and educators. There are also opportunities to use the same
  software environment creation to support outreach and
  citizen-science projects (see~\ref{sec:mybinder}). A set of representatives of
  these domains will be gathered in the Community Engagement Panel, and connect
  us with the relevant communities. A list of confirmed panel members is
  available (see~\taskref{management}{community-engagement-panel}) and will be
  extended if the project is funded.
\item The design idea for \repotodocker{} is to build on existing standards and
  conventions. This means that researchers have already created reproducible
  repositories (if they use those conventions to specify software requirements),
  but we have not developed the tool yet to create the software for that
  repository automatically. Following this design choice means that we do not
  expect researchers to learn something just so that \repotodocker{} can
  understand it.
\item Providing useful training plays a key role in enabling and motivating
  researchers to work reproducible. We will explain the benefits for
  reproducible work, and teach good practice for reproducible science such as
  keeping raw data,  meta data and relevant software, using version control and
  automating analysis steps and workflows.
  We will also showcase tools to support the creation (and use) of reproducible
  research artifacts, including those developed through this project.
\item We will explain the possibility of using Jupyter notebooks to create
  reproducible records of computational science, but also support non-notebook
  driven use cases.
\item The measures we advocate to improve reproducibility in science are
  designed to be embedded into the ongoing research activity to minimise the
  additional burden associated with the publication of results.
\item We believe in an agile approach to effective software engineering to get
  the most useful and fast feedback from the use of those features in a real
  world context.
\item All our outputs will be open source and published with permissive
  licenses.
\end{compactenum}


\medskip
\noindent We implement our approach through 5 Work packages:

%\begin{itemize}
%\item
\WPref{management} deals with the admininstrative~(\taskref{management}{admin})
and technical~(\taskref{management}{project-management}) management of the
project, and the organisation of the Community Engagement
Panel~(\taskref{management}{community-engagement-panel}).
    % \item

    \WPref{reproducibility} will improve the robustness of reproducible
    environments through technical work on \repotodocker{} and BinderHub. In
    particular, we will first create a metric to be able to measure our progress
    (\taskref{reproducibility}{repo2docker-checker}), improve the ability create
    software environments for older repositories
    (\taskref{reproducibility}{repo2docker-timemachine}) and improve the
    performance (\taskref{reproducibility}{performance-optimisation}). We
    explicitly allocate some time in \taskref{reproducibility}{maintenance} for
    maintaining the tools we extend and want to build on. Maintenance is crucial
    to creating reliable, sustainable software, but its cost is often swept
    under the rug in funding applications because of the perceived pressure to
    focus on novelty.
    % \item

    \WPref{impact} will extend the feature set of \repotodocker{} to broaden
    the impact of the project. This
    includes to understand more data sources and software specification patters
    (\taskref{impact}{buildpacks}), to refactor the tool to not depend on a
    Kubernetis installation and support other container formats next to Docker
    (\taskref{impact}{constraints}), to export identified software dependencies,
    to support new use cases and to
    better support use outside the Jupyter ecosystem (\taskref{impact}{patterns}).
    % \item

    \WPref{applications} will test, evaluate and apply the improvements from
    work packages \WPref{reproducibility} and \WPref{impact} in real-world
    reproducibility use cases, such as best practice reproducibility show
    cases~(\taskref{applications}{demos}), use of \repotodocker{} on
    decentralised hardware~(\taskref{applications}{binder-at-home}), publishing
    of large, complex or restricted access data
    sets~(\taskref{applications}{data-publishing}), and reproducibility for HPC~
    (\taskref{applications}{binder-at-hpc}).
    % \item

    \WPref{education} disseminates outcomes, delivers training materials
    and activities, and supports community engagement. We will develop best practice guidelines for reproducible
    science (\taskref{education}{online-resources}), organise and deliver
    training events (\taskref{education}{workshops}), work closely with
    scientists wishing to contribute to the project (\taskref{education}{community-support}).
  %\end{itemize}

%
% \textbf{Improving the robustness of reproducible environments (\WPref{reproducibility})}\\
% Finally, we are explicitly allocating time in \WPref{reproducibility} for maintaining
% Jupyter software, as well as new development
%  % (\taskref{reproducibility}{maintenance}).
% Maintenance is crucial to creating reliable, sustainable software,
% but its cost is often swept under the rug in funding applications
% because of the perceived pressure to focus on novelty.
% Being up front and explicit about this cost is critical to the sustainability
% of open source open science.
%
% \medskip
% \noindent\textbf{Broadening  (\WPref{impact})}\\
% In addition to improving how successfully and how often tools like \repotodocker{} reproduce environments,
% we aim to broaden the impact of the tools by making them useful in more contexts.
% The existing software makes certain assumptions about where it will run,
% made for the purposes of limiting maintenance scope of the Binder project.
% As the project has matured, certain expansions of scope are appropriate,
% as seen in the existing demand for new features in the project.
%
% We further propose improvements to the wider Binder ecosystem
% to expand the impact of the tools in more contexts to be useful to more researchers
% and more institutions.
% In particular, we have identified planned improvements:
%
% \begin{itemize}
%   \item Binder and its crucial software component \emph{repo2docker}
%   \item relaxing Kubernetes assumption
%   \item running on HPC
%   \item more buildpacks
%     % (\taskref{ecosystem}{r2d-and-binder}).
%
% \end{itemize}
%

%   \medskip\noindent\textbf{Beyond the improvement to \TheProject tools
%   (\WPref{applications}, \WPref{education})}\\
% Beyond the improvement to the Binder tools for reproducility, we plan on
% \begin{itemize}
% \item Design, implementation, application, demonstration and
%   evaluation of multiple demonstrators, that cover research fields such as
%   \TOWRITE{}{photon and neutron science, geosciences},
%   and also interests of participating SMEs (\WPref{applications}).
% \item Producing \emph{training and education material} to disseminate
%   the ability to do reproducible computational science using the tools
%   we develop, among others (\WPref{education}).
% \end{itemize}
%
% \medskip
% \noindent
% \textbf{The science
%   demonstrators}\label{sec:science-demonstrators-in-concept}\\
%
% We describe the context and challenges for each demonstrator in this
% section. The particular planned activities are shown in the
% corresponding tasks in \WPref{applications}.


\subsubsection{Gender aspects}\label{sec:gender}

\eucommentary{Describe how the gender dimension (i.e. sex and/or gender
  analysis) is taken into account in the project's research and innovation
  content [e.g. 1 page]. If you do not consider such a gender dimension to be
  relevant in your project, please provide a justification.}

\eucommentary{
	Note: This section is mandatory except for topics which have been identified
  in the work programme as not requiring the integration of the gender dimension
  into R\&I content.
}

\eucommentary{
	Remember that that this question relates to the content of the planned
  research and innovation activities, and not to gender balance in the teams in
  charge of carrying out the project.
}

\eucommentary{
	Sex and gender analysis refers to biological characteristics and
  social/cultural factors respectively. For guidance on methods of sex/gender
  analysis and the issues to be taken into account, please refer to
  \url{https://ec.europa.eu/info/news/gendered-innovations-2-2020-nov-24\_en}
}

In order to address gender issues, \TheProject is committed to implement
communication and outreach activities for promoting the role of women and underrepresented groups in science
and STEM: i) present showcases to demonstrate the results of the project through
the eyes of female Research Software Engineers and researchers; ii)
systematically offer hybrid or online training opportunities to encompass the
lack of mobility of some potential attendees; iii) monitor gender participation
to our training, workshops, and hackathons and track progress. Members of the
consortium are involved in a number of programmes and activities who aim at
upskilling women and diversity and inclusion, for instance The Carpentries and
CodeRefinery training programmes and mentoring programs such as Outreachy or
Open Life Science.

\subsubsection{National and international research or innovation activities}

\eucommentary{Describe any national or international research and innovation
  activities whose results will feed into the project, and how that link will be
  established; [e.g. 1 pages]}
\TOWRITE{}{}

The SOURCE project, as part of the overall jupyter environment, will intrinsically build on the achievements of many national and European and international research and innovative developments, which have been produced or are being implemented in research projects in which research infrastructures and project partners are or have been involved.
Table~\ref{tab:national-research} shows a selection of highly relevant projects in different areas and coordinated and/or conducted by \TheProject partners.



\begin{table}[]
\label{tab:national-research}
\begin{tabular}{lll}
\rowcolor[HTML]{00D2CB}

Project Name  & Country & Description of the linked project and how that link will be established \\
Digital Twin  &         &                                                                         \\
Digital ocean &         &                                                                         \\
              &         &                                                                         \\
              &         &

\end{tabular}
\end{table}




\subsubsection{Interdisciplinarity}

\eucommentary{Explain how expertise and methods from different disciplines will be brought together and integrated in pursuit of your objectives. If you consider that an inter-disciplinary approach is unnecessary in the context of the proposed work, please provide a justification. [e.g. 1/2 page]
}
\TOWRITE{}{}

\subsubsection{Open science practices and implementation}

\TheProject will make use of open source licensed software, packages and libraries, following the \href{https://opensource.org/licenses}{OSI recommendations}.

All codes in this project will be Open Source and collaboratively developed using GitHub, following best software engineering practice
such as version control, tests and continuous integration.
Training materials will be collaboratively developed through the \href{https://carpentries-incubator.org/}{Carpentries Incubator}
using the \href{https://cdh.carpentries.org/}{Carpentries Curriculum Development Handbook}: all Carpentries lessons are licensed under
the \href{https://creativecommons.org/licenses/by/4.0/legalcode}{Creative Commons Attribution version 4.0 (CC-BY)} and any related software under
the \href{https://opensource.org/licenses/MIT}{MIT license}.

Use cases and showcases will only make use of data that are openly available.

All publications and/or any research data produced within \TheProject will be published Open Access.


\eucommentary{Describe how appropriate open science practices are implemented as
   an integral part of the proposed methodology. Show how the choice of practices
   and their implementation are adapted to the nature of your work, in a way that
   will increase the chances of the project delivering on its objectives [e.g. 1
   page].
%
   If you believe that none of these practices are appropriate for your
   project, please provide a justification here.
   }

\eucommentary{Open science is an approach based on open cooperative work and systematic
   sharing of knowledge and tools as early and widely as possible in the process.
   Open science practices include early and open sharing of research (for example
   through preregistration, registered reports, pre-prints, or crowd-sourcing);
   research output management; measures to ensure reproducibility of research
   outputs; providing open access to research outputs (such as publications,
   data, software, models, algorithms, and workflows); participation in open
   peer-review; and involving all relevant knowledge actors including citizens,
   civil society and end users in the co-creation of R\&I agendas and contents
   (such as citizen science).}

\eucommentary{Please note that this question does not refer to outreach actions that may be
   planned as part of communication, dissemination and exploitation activities.
These aspects should instead be described below under 'Impact'.}

\TOWRITE{}{}

\subsubsection{Research Data Management and management of other outputs}

The Data Management Plan (DMP) will be prepared and regularly updated within WP1.

Except for the usage data described below,
\TheProject activities will not generate or collect data.
While we have many demonstrators that interact with data, they do not generate or collect that
data themselves, but rather provide analytical mechanisms or access to data governed by
existing data management plans and data policies of project partners at each site,
as well as publicly accessible open data.

All data generated, collected, processed and stored will be made available following the
relevant standards and regulations. Processing of personal data in relation to training,
hackathons and/or workshop events will comply with GDPR regulations e.g. data
anonymization and minimization before sharing.
Procedures to monitor the real-time effectiveness of our dissemination and
communication strategies will also be GDPR compliant.
We have no plans to collect or produce PII during the project.

\noindent \textbf{Service usage data} \\
Any data collected through the operation of public services
(e.g. popularity data for public open science repositories)
will be fully anonymised to the satisfaction of relevant best privacy practices and regulations, such as GDPR,
and made publicly available in the standard JSON Lines format,
as is done already for mybinder.org \cite{mybinder-archive}.
This is very small data and easily archived on free hosting services such as GitHub,
and will be made available under the Creative-Commons Universal Public Domain Dedication (CC0).
There is no cost to the project associated with archiving this data long-term.


\eucommentary{
Research data management and management of other research outputs: Applicants
generating/collecting data and/or other research outputs (except for
publications) during the project must provide maximum 1 page on how the data/
research outputs will be managed in line with the FAIR principles (Findable,
Accessible, Interoperable, Reusable), addressing the following (the description
should be specific to your project): [1 page]
}

\eucommentary{
Types of data/research outputs (e.g. experimental, observational, images, text,
numerical) and their estimated size; if applicable, combination with, and
provenance of, existing data.
}

\eucommentary{
Findability of data/research outputs: Types of persistent and uniqueidentifiers
(e.g. digital object identifiers) and trusted repositories that will be used.
}

\eucommentary{
Accessibility of data/research outputs: IPR considerations and timeline for open
access (if open access not provided, explain why); provisions for access to
restricted data for verification purposes.
}

\eucommentary{
Interoperability of data/research outputs: Standards, formats and vocabularies
for data and metadata. Reusability of data/research outputs:  Licenses for data
sharing and re-use (e.g. Creative Commons, Open Data Commons); availability of
tools/software/models for data generation. }

\TOWRITE{}{}

\begin{draft}
\section*{Todo list for missing subsections}
\begin{verbatim}
- [ ] 1 page: National or international research or innovation activities
- [ ] 0.5 page: bringing together expertise and methods from different disciplines
- [ ] 0.5 page: social science and humanities - how do we integrate them, or why do we not need them
- [X] 1 page: gender dimension.
- [ ] 1 page: open science practices and implementation
- [ ] 1 page: research data management and management of other research outputs. (Also FAIR)
\end{verbatim}
\end{draft}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "proposal"
%%% End:
